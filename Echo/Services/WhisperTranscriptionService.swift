import Foundation
import WhisperKit

/// –û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ WhisperKit –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.
///
/// –ó–∞–º–µ–Ω—è–µ—Ç FluidAudio AsrManager (Parakeet), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–ª —Ç–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π.
/// WhisperKit –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –º–æ–¥–µ–ª–∏ OpenAI Whisper, –Ω–∞—Ç–∏–≤–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ–¥ Apple Silicon.
///
/// –í–ê–ñ–ù–û: WhisperKit –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ç–∏–ø—ã TranscriptionResult / TranscriptionSegment, –∫–æ—Ç–æ—Ä—ã–µ
/// –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É—é—Ç —Å –æ–¥–Ω–æ–∏–º—ë–Ω–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏ –≤ –Ω–∞—à–µ–º –º–æ–¥—É–ª–µ. –ü–æ—ç—Ç–æ–º—É –º—ã –≤–µ–∑–¥–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã–≤–æ–¥ —Ç–∏–ø–æ–≤
/// –∏ –ù–ï –ø–∏—à–µ–º —è–≤–Ω—ã–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –¥–ª—è —Ç–∏–ø–æ–≤ WhisperKit ‚Äî —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–º–ø–∏–ª—è—Ç–æ—Ä—É –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
/// –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∏—Ö —á–µ—Ä–µ–∑ —Å–∏–≥–Ω–∞—Ç—É—Ä—É –º–µ—Ç–æ–¥–∞ whisperKit.transcribe(audioArrays:).
@MainActor
final class WhisperTranscriptionService: ObservableObject {

    enum WhisperError: LocalizedError {
        case modelsNotLoaded
        case transcriptionFailed(String)

        var errorDescription: String? {
            switch self {
            case .modelsNotLoaded:
                return "–ú–æ–¥–µ–ª–∏ Whisper –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã. –°–Ω–∞—á–∞–ª–∞ –≤—ã–∑–æ–≤–∏—Ç–µ prepareModels()"
            case .transcriptionFailed(let m):
                return "–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: \(m)"
            }
        }
    }

    @Published var isLoadingModels = false
    @Published var modelsReady = false

    private var whisperKit: WhisperKit?

    // –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ ‚Äî –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏:
    //   openai_whisper-large-v3  ‚Äî –ª—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (~3 GB)
    //   openai_whisper-medium    ‚Äî —Ö–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ (~1.5 GB)
    //   openai_whisper-small     ‚Äî –±—ã—Å—Ç—Ä–µ–µ (~244 MB)
    static let modelName = "openai_whisper-large-v3"

    // MARK: ‚Äì –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–æ–¥–µ–ª–µ–π

    func prepareModels() async throws {
        guard !modelsReady else { return }
        isLoadingModels = true
        defer { isLoadingModels = false }

        print("‚è≥ WhisperKit: –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ \(Self.modelName)...")
        let wk = try await WhisperKit(
            model: Self.modelName,
            verbose: false
        )
        self.whisperKit = wk
        self.modelsReady = true
        print("‚úÖ WhisperKit –≥–æ—Ç–æ–≤")
    }

    // MARK: ‚Äì –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è

    /// –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –º–∞—Å—Å–∏–≤ PCM-—Å—ç–º–ø–ª–æ–≤ (16 kHz, mono, Float32).
    ///
    /// - Parameters:
    ///   - samples: Float32 16kHz mono PCM –∞—É–¥–∏–æ
    ///   - language: –ö–æ–¥ —è–∑—ã–∫–∞ ("ru", "en", "" = –∞–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
    ///   - onProgress: –ö–æ–ª–ª–±—ç–∫ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ 0.0‚Äì1.0
    /// - Returns: `EchoASRResult` —Å –ø–æ—Å–ª–æ–≤–Ω—ã–º–∏ —Ç–∞–π–º–∏–Ω–≥–∞–º–∏
    func transcribeRaw(
        samples: [Float],
        language: String = "ru",
        onProgress: @escaping (Double) -> Void = { _ in }
    ) async throws -> EchoASRResult {
        guard let whisperKit else { throw WhisperError.modelsNotLoaded }

        let lang: String? = language.isEmpty ? nil : language

        var options = DecodingOptions()
        options.language = lang
        options.wordTimestamps = true
        options.skipSpecialTokens = true
        options.task = .transcribe

        print("üåç WhisperKit: —è–∑—ã–∫=\(lang ?? "–∞–≤—Ç–æ"), samples=\(samples.count)")

        // transcribe(audioArrays:) –ø—Ä–∏–Ω–∏–º–∞–µ—Ç [[Float]], –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç [[TranscriptionResult]?]
        // –¢–∏–ø—ã –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –≤—ã–≤–æ–¥—è—Ç—Å—è, –∞ –Ω–µ –∑–∞–ø–∏—Å—ã–≤–∞—é—Ç—Å—è —è–≤–Ω–æ, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –∏–º—ë–Ω
        // –º–µ–∂–¥—É WhisperKit.TranscriptionResult –∏ –Ω–∞—à–∏–º Echo.TranscriptionResult.
        let batchResults = await whisperKit.transcribe(
            audioArrays: [samples],
            decodeOptions: options
        )

        var allText = ""
        var duration: Double = 0
        var detectedLang = language
        var tokenTimings: [EchoTokenTiming] = []

        // batchResults: [[TranscriptionResult]?] ‚Äî –æ–¥–∏–Ω —ç–ª–µ–º–µ–Ω—Ç (–º—ã –ø–µ—Ä–µ–¥–∞–ª–∏ –æ–¥–∏–Ω –º–∞—Å—Å–∏–≤)
        for outerOptional in batchResults {
            guard let resultsArray = outerOptional else { continue }
            for result in resultsArray {
                if !result.language.isEmpty {
                    detectedLang = result.language
                }
                allText += result.text + " "

                for segment in result.segments {
                    duration = max(duration, Double(segment.end))

                    guard let words = segment.words else { continue }
                    for word in words {
                        let cleaned = word.word.trimmingCharacters(in: .whitespaces)
                        guard !cleaned.isEmpty else { continue }
                        tokenTimings.append(EchoTokenTiming(
                            token: cleaned,
                            startTime: Double(word.start),
                            endTime: Double(word.end)
                        ))
                    }
                }
            }
        }

        allText = allText.trimmingCharacters(in: .whitespaces)

        print("‚úÖ WhisperKit: \(tokenTimings.count) —Å–ª–æ–≤, –¥–ª–∏–Ω–∞=\(String(format: "%.1f", duration))s, —è–∑—ã–∫=\(detectedLang)")
        if tokenTimings.isEmpty {
            print("‚ö†Ô∏è  WhisperKit: –Ω–µ—Ç –ø–æ—Å–ª–æ–≤–Ω—ã—Ö —Ç–∞–π–º–∏–Ω–≥–æ–≤ ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ wordTimestamps")
        }

        return EchoASRResult(
            text: allText,
            duration: duration,
            tokenTimings: tokenTimings.isEmpty ? nil : tokenTimings,
            language: detectedLang
        )
    }
}
