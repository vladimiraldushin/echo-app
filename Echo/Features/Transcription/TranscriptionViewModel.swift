import Foundation
import SwiftUI
import FluidAudio  // Ğ”Ğ»Ñ DiarizerConfig

@MainActor
final class TranscriptionViewModel: ObservableObject {

    enum State {
        case idle
        case converting
        case transcribing(progress: Double)
        case diarizing
        case completed
        case failed(String)

        var statusText: String {
            switch self {
            case .idle:                      return "ĞĞ¶Ğ¸Ğ´Ğ°Ğ½Ğ¸Ğµ"
            case .converting:                return "ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾..."
            case .transcribing(let p):       return "Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ \(Int(p * 100))%"
            case .diarizing:                 return "ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²..."
            case .completed:                 return "Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾"
            case .failed(let msg):           return "ĞÑˆĞ¸Ğ±ĞºĞ°: \(msg)"
            }
        }

        var progress: Double {
            switch self {
            case .converting:            return 0.1
            case .transcribing(let p):   return 0.1 + p * 0.6
            case .diarizing:             return 0.8
            case .completed:             return 1.0
            default:                     return 0
            }
        }

        var isProcessing: Bool {
            if case .converting = self { return true }
            if case .transcribing = self { return true }
            if case .diarizing = self { return true }
            return false
        }
    }

    @Published var state: State = .idle
    @Published var result: TranscriptionResult?
    @Published var selectedLanguage = "ru"
    @Published var searchQuery = ""
    @Published var expectedSpeakers: Int = -1  // -1 = Ğ°Ğ²Ñ‚Ğ¾Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ, 2+ = Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾

    var filteredSegments: [Segment] {
        guard let result else { return [] }
        let sorted = result.sortedSegments
        guard !searchQuery.isEmpty else { return sorted }
        return sorted.filter { $0.text.localizedCaseInsensitiveContains(searchQuery) }
    }

    private let converter = AudioConverter()
    private let whisperService = WhisperTranscriptionService()
    private let diarizationService = DiarizationService()
    private let aligner = SpeakerAligner()
    private let audioDiagnostics = AudioDiagnostics()

    // MARK: â€“ ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ°Ğ¹Ğ¿Ğ»Ğ°Ğ¹Ğ½

    func process(file: AudioFile) async {
        state = .converting

        do {
            print("\n")
            print("ğŸš€ ĞĞĞ§ĞĞ›Ğ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ˜: \(file.name)")
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")

            // 1. ĞšĞ¾Ğ½Ğ²ĞµÑ€Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ² 16kHz mono Float32
            let samples = try await converter.convert(url: file.url)

            // 1Ğ±. Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ° ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ°ÑƒĞ´Ğ¸Ğ¾
            let audioQuality = await audioDiagnostics.analyze(samples: samples)
            print(audioQuality.description)

            // 2. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° WhisperKit (Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸, ĞµÑĞ»Ğ¸ ĞµÑ‰Ñ‘ Ğ½Ğµ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ°)
            if !whisperService.modelsReady {
                print("â³ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ WhisperKit...")
                try await whisperService.prepareModels()
                print("âœ… WhisperKit Ğ³Ğ¾Ñ‚Ğ¾Ğ²\n")
            }

            // 2Ğ±. ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ (FluidAudio)
            if !diarizationService.modelsReady {
                print("â³ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸...")
                try await diarizationService.prepareModels()
                print("âœ… ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹\n")
            }

            // 3. Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ñ‡ĞµÑ€ĞµĞ· WhisperKit (Whisper large-v3, Ñ€ÑƒÑÑĞºĞ¸Ğ¹)
            state = .transcribing(progress: 0)

            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print("ğŸ“ Ğ­Ğ¢ĞĞŸ 1: Ğ¢Ğ ĞĞĞ¡ĞšĞ Ğ˜ĞŸĞ¦Ğ˜Ğ¯ (WhisperKit)")
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
            print("ğŸŒ Ğ¯Ğ·Ñ‹Ğº: \(selectedLanguage.isEmpty ? "Ğ°Ğ²Ñ‚Ğ¾" : selectedLanguage.uppercased())")

            let asrResult = try await whisperService.transcribeRaw(
                samples: samples,
                language: selectedLanguage,
                onProgress: { [weak self] progress in
                    Task { @MainActor [weak self] in
                        self?.state = .transcribing(progress: progress)
                    }
                }
            )

            print("\nâœ… Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°:")
            print("   â€¢ Ğ¡Ğ»Ğ¾Ğ²: \(asrResult.tokenTimings?.count ?? 0)")
            print("   â€¢ Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: \(String(format: "%.1f", asrResult.duration))s")
            print("   â€¢ Ğ¡Ğ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ: \(asrResult.text.count)")
            print("   â€¢ Ğ¯Ğ·Ñ‹Ğº: \(asrResult.language)")
            if let firstToken = asrResult.tokenTimings?.first,
               let lastToken  = asrResult.tokenTimings?.last {
                print("   â€¢ Ğ”Ğ¸Ğ°Ğ¿Ğ°Ğ·Ğ¾Ğ½: [\(String(format: "%.2f", firstToken.startTime))s â€“ \(String(format: "%.2f", lastToken.endTime))s]")
            }

            // 4. Ğ”Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ², FluidAudio)
            state = .diarizing

            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print("ğŸ™ï¸  Ğ­Ğ¢ĞĞŸ 2: Ğ”Ğ˜ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ¯ (ĞĞŸĞ Ğ•Ğ”Ğ•Ğ›Ğ•ĞĞ˜Ğ• Ğ¡ĞŸĞ˜ĞšĞ•Ğ ĞĞ’)")
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

            var diarizationConfig = OfflineDiarizerConfig.default

            if expectedSpeakers > 0 {
                diarizationConfig.clustering.numSpeakers = expectedSpeakers
                print("âš™ï¸  ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:")
                print("   â€¢ Ğ ĞµĞ¶Ğ¸Ğ¼: Ñ„Ğ¸ĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ñ‡Ğ¸ÑĞ»Ğ¾ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ² = \(expectedSpeakers)\n")
            } else {
                // 0.3 â€” ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ğ¾Ğ³, Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ñ€Ğ°Ğ·Ğ´ĞµĞ»ÑĞµÑ‚ Ğ³Ğ¾Ğ»Ğ¾ÑĞ°
                diarizationConfig.clusteringThreshold = 0.3
                print("âš™ï¸  ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸:")
                print("   â€¢ Ğ ĞµĞ¶Ğ¸Ğ¼: Ğ°Ğ²Ñ‚Ğ¾-Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ, clusteringThreshold=0.3\n")
            }

            let diarizationResult = try await diarizationService.diarize(
                samples: samples,
                config: diarizationConfig
            )

            // Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ¸Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
            let diarizationAnalysis = DiarizationDiagnostics.analyze(diarizationResult)
            print(diarizationAnalysis.description)
            print(DiarizationDiagnostics.visualizeTimeline(diarizationResult, width: 60))

            // 5. Ğ’Ñ‹Ñ€Ğ°Ğ²Ğ½Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ: diarization-driven ÑĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print("ğŸ”— Ğ­Ğ¢ĞĞŸ 3: Ğ’Ğ«Ğ ĞĞ’ĞĞ˜Ğ’ĞĞĞ˜Ğ• (Ğ¡Ğ›ĞĞ’Ğ â†’ Ğ¡Ğ•Ğ“ĞœĞ•ĞĞ¢Ğ« Ğ”Ğ˜ĞĞ Ğ˜Ğ—ĞĞ¦Ğ˜Ğ˜)")
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

            let aligned = aligner.buildSegments(from: asrResult, diarization: diarizationResult)
            let numSpeakers = aligner.speakerCount(from: diarizationResult)

            print("\nğŸ“‹ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ½Ğ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹:")
            for (i, seg) in aligned.prefix(5).enumerated() {
                print("  [\(i)] Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ \(seg.speakerIndex): \"\(seg.text.prefix(60))\"")
                print("       [\(String(format: "%.2f", seg.startTime))s â€“ \(String(format: "%.2f", seg.endTime))s]\n")
            }

            // 6. Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
            print("âœ… Ğ¡Ğ‘ĞĞ ĞšĞ Ğ¤Ğ˜ĞĞĞ›Ğ¬ĞĞĞ“Ğ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ")
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

            let transcriptionResult = TranscriptionResult(language: asrResult.language)

            for i in 0..<numSpeakers {
                transcriptionResult.speakers.append(Speaker(index: i))
            }

            for (order, seg) in aligned.enumerated() {
                let segment = Segment(
                    text: seg.text,
                    startTime: seg.startTime,
                    endTime: seg.endTime,
                    speakerIndex: seg.speakerIndex,
                    order: order
                )
                transcriptionResult.segments.append(segment)
            }

            self.result = transcriptionResult

            print("ğŸ“Š Ğ˜Ñ‚Ğ¾Ğ³Ğ¾:")
            print("   â€¢ Ğ¡ĞµĞ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ²: \(transcriptionResult.segments.count)")
            print("   â€¢ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²: \(numSpeakers)")
            print("   â€¢ Ğ¯Ğ·Ñ‹Ğº: \(asrResult.language)")
            print("\nğŸ‰ ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ—ĞĞ’Ğ•Ğ Ğ¨Ğ•ĞĞ Ğ£Ğ¡ĞŸĞ•Ğ¨ĞĞ!")
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")

            state = .completed

        } catch {
            print("\nâŒ ĞĞ¨Ğ˜Ğ‘ĞšĞ: \(error.localizedDescription)")
            print("â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
            state = .failed(error.localizedDescription)
        }
    }

    // MARK: â€“ Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚

    func export(format: ExportService.ExportFormat) {
        guard let result else { return }

        let panel = NSSavePanel()
        panel.allowedContentTypes = []
        panel.nameFieldStringValue = "transcription.\(format.rawValue)"
        panel.title = "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ†Ğ¸Ñ"

        if panel.runModal() == .OK, let url = panel.url {
            let dir = url.deletingLastPathComponent()
            let name = url.deletingPathExtension().lastPathComponent
            do {
                let exported = try ExportService().export(
                    result: result, to: dir, format: format, filename: name
                )
                NSWorkspace.shared.activateFileViewerSelecting([exported])
            } catch {
                // TODO: Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ°Ğ»ĞµÑ€Ñ‚
            }
        }
    }

    // MARK: â€“ Ğ ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ

    func renameSpeaker(index: Int, newName: String) {
        result?.speakers.first(where: { $0.index == index })?.name = newName
    }
}
