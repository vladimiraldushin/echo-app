import Foundation
import Accelerate

/// –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∞—É–¥–∏–æ –∏ –∞–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
actor AudioDiagnostics {
    
    struct AudioQuality {
        let sampleRate: Double
        let duration: Double
        let sampleCount: Int
        
        // –£—Ä–æ–≤–Ω–∏ –≥—Ä–æ–º–∫–æ—Å—Ç–∏
        let averageLevel: Float      // –°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å (dB)
        let peakLevel: Float          // –ü–∏–∫–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å (dB)
        let dynamicRange: Float       // –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω (dB)
        
        // –®—É–º –∏ –∫–∞—á–µ—Å—Ç–≤–æ
        let noiseFloor: Float         // –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞ (dB)
        let signalToNoiseRatio: Float // SNR (dB)
        let clipPercentage: Float     // % –∫–ª–∏–ø–ø–∏–Ω–≥–∞
        
        // –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ä–µ—á–∏
        let speechPercentage: Float   // % –≤—Ä–µ–º–µ–Ω–∏ —Å —Ä–µ—á—å—é
        let silencePercentage: Float  // % –≤—Ä–µ–º–µ–Ω–∏ —Ç–∏—à–∏–Ω—ã
        let averagePauseDuration: Float // –°—Ä–µ–¥–Ω—è—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–∞—É–∑
        
        // –ö–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        var qualityRating: QualityRating {
            if signalToNoiseRatio > 30 && clipPercentage < 1.0 && speechPercentage > 20 {
                return .excellent
            } else if signalToNoiseRatio > 20 && clipPercentage < 5.0 && speechPercentage > 10 {
                return .good
            } else if signalToNoiseRatio > 10 && clipPercentage < 15.0 {
                return .acceptable
            } else {
                return .poor
            }
        }
        
        enum QualityRating: String {
            case excellent = "–û—Ç–ª–∏—á–Ω–æ"
            case good = "–•–æ—Ä–æ—à–æ"
            case acceptable = "–ü—Ä–∏–µ–º–ª–µ–º–æ"
            case poor = "–ü–ª–æ—Ö–æ"
        }
        
        var description: String {
            """
            
            ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            üìä –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ê–£–î–ò–û
            ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            ‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:       \(String(format: "%.1f", duration))—Å (\(sampleCount) —Å—ç–º–ø–ª–æ–≤ @ \(Int(sampleRate))Hz)
            
            üîä –£–†–û–í–ù–ò –°–ò–ì–ù–ê–õ–ê:
               ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å:    \(String(format: "%+.1f", averageLevel)) dB
               ‚Ä¢ –ü–∏–∫–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å:    \(String(format: "%+.1f", peakLevel)) dB
               ‚Ä¢ –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω: \(String(format: "%.1f", dynamicRange)) dB
            
            üì° –ö–ê–ß–ï–°–¢–í–û –°–ò–ì–ù–ê–õ–ê:
               ‚Ä¢ –£—Ä–æ–≤–µ–Ω—å —à—É–º–∞:       \(String(format: "%+.1f", noiseFloor)) dB
               ‚Ä¢ –û—Ç–Ω–æ—à–µ–Ω–∏–µ –°/–®:      \(String(format: "%.1f", signalToNoiseRatio)) dB \(snrIcon)
               ‚Ä¢ –ö–ª–∏–ø–ø–∏–Ω–≥:           \(String(format: "%.2f", clipPercentage))% \(clipIcon)
            
            üéôÔ∏è  –†–ï–ß–ï–í–ê–Ø –ê–ö–¢–ò–í–ù–û–°–¢–¨:
               ‚Ä¢ –†–µ—á—å:               \(String(format: "%.1f", speechPercentage))%
               ‚Ä¢ –¢–∏—à–∏–Ω–∞:             \(String(format: "%.1f", silencePercentage))%
               ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –ø–∞—É–∑–∞:      \(String(format: "%.2f", averagePauseDuration))—Å
            
            ‚≠êÔ∏è –û–ë–©–ê–Ø –û–¶–ï–ù–ö–ê:        \(qualityRating.rawValue) \(qualityIcon)
            
            \(recommendations)
            ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            """
        }
        
        private var snrIcon: String {
            if signalToNoiseRatio > 30 { return "‚úÖ" }
            if signalToNoiseRatio > 20 { return "üü°" }
            return "‚ö†Ô∏è"
        }
        
        private var clipIcon: String {
            if clipPercentage < 1.0 { return "‚úÖ" }
            if clipPercentage < 5.0 { return "üü°" }
            return "‚ö†Ô∏è"
        }
        
        private var qualityIcon: String {
            switch qualityRating {
            case .excellent: return "üåü"
            case .good: return "‚úÖ"
            case .acceptable: return "üü°"
            case .poor: return "‚ùå"
            }
        }
        
        private var recommendations: String {
            var issues: [String] = []
            
            if signalToNoiseRatio < 15 {
                issues.append("‚ö†Ô∏è  –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —à—É–º–∞ ‚Äî —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —à—É–º–æ–ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ")
            }
            if clipPercentage > 5.0 {
                issues.append("‚ö†Ô∏è  –û–±–Ω–∞—Ä—É–∂–µ–Ω –∫–ª–∏–ø–ø–∏–Ω–≥ ‚Äî –∞—É–¥–∏–æ –ø–µ—Ä–µ–≥—Ä—É–∂–µ–Ω–æ")
            }
            if speechPercentage < 10 {
                issues.append("‚ö†Ô∏è  –ú–∞–ª–æ —Ä–µ—á–µ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ ‚Äî –≤–æ–∑–º–æ–∂–Ω–æ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–∞–π–ª?")
            }
            if dynamicRange < 10 {
                issues.append("‚ö†Ô∏è  –ù–∏–∑–∫–∏–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω ‚Äî —Å–∂–∞—Ç–æ–µ –∞—É–¥–∏–æ")
            }
            if averagePauseDuration < 0.3 {
                issues.append("‚ÑπÔ∏è  –ö–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—É–∑—ã ‚Äî –≤–æ–∑–º–æ–∂–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π")
            }
            
            if issues.isEmpty {
                return "‚úÖ –ê—É–¥–∏–æ –æ—Ç–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏!\n"
            } else {
                return "–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:\n" + issues.map { "   \($0)" }.joined(separator: "\n") + "\n"
            }
        }
    }
    
    // MARK: - –ê–Ω–∞–ª–∏–∑
    
    func analyze(samples: [Float], sampleRate: Double = 16000) -> AudioQuality {
        let sampleCount = samples.count
        let duration = Double(sampleCount) / sampleRate
        
        // –í—ã—á–∏—Å–ª—è–µ–º —É—Ä–æ–≤–Ω–∏
        let avgLevel = averageLevel(samples)
        let peakLevel = peakLevel(samples)
        let noiseFloor = noiseFloor(samples)
        let dynamicRange = peakLevel - avgLevel
        let snr = avgLevel - noiseFloor
        let clipPercentage = clippingPercentage(samples)
        
        // –ê–Ω–∞–ª–∏–∑ —Ä–µ—á–µ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        let (speechPct, silencePct, avgPause) = speechActivity(samples, sampleRate: sampleRate)
        
        return AudioQuality(
            sampleRate: sampleRate,
            duration: duration,
            sampleCount: sampleCount,
            averageLevel: avgLevel,
            peakLevel: peakLevel,
            dynamicRange: dynamicRange,
            noiseFloor: noiseFloor,
            signalToNoiseRatio: snr,
            clipPercentage: clipPercentage,
            speechPercentage: speechPct,
            silencePercentage: silencePct,
            averagePauseDuration: avgPause
        )
    }
    
    // MARK: - –ü—Ä–∏–≤–∞—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã
    
    private func averageLevel(_ samples: [Float]) -> Float {
        var sum: Float = 0.0
        vDSP_meamgv(samples, 1, &sum, vDSP_Length(samples.count))
        return amplitudeToDecibels(sum)
    }
    
    private func peakLevel(_ samples: [Float]) -> Float {
        var peak: Float = 0.0
        vDSP_maxv(samples.map(abs), 1, &peak, vDSP_Length(samples.count))
        return amplitudeToDecibels(peak)
    }
    
    private func noiseFloor(_ samples: [Float]) -> Float {
        // –ë–µ—Ä—ë–º –Ω–∏–∂–Ω–∏–µ 10% –ø–æ –∞–º–ø–ª–∏—Ç—É–¥–µ ‚Äî —ç—Ç–æ —à—É–º
        let sorted = samples.map(abs).sorted()
        let noiseIndex = samples.count / 10
        let noise = sorted[noiseIndex]
        return amplitudeToDecibels(max(noise, 0.0001))
    }
    
    private func clippingPercentage(_ samples: [Float]) -> Float {
        let threshold: Float = 0.99
        let clipped = samples.filter { abs($0) > threshold }.count
        return Float(clipped) / Float(samples.count) * 100.0
    }
    
    private func speechActivity(_ samples: [Float], sampleRate: Double) -> (speech: Float, silence: Float, avgPause: Float) {
        let frameSize = 400  // 25ms @ 16kHz
        let threshold: Float = 0.02
        
        var speechFrames = 0
        var silenceFrames = 0
        var pauseDurations: [Float] = []
        var currentPauseDuration = 0
        
        for i in stride(from: 0, to: samples.count - frameSize, by: frameSize) {
            let frame = Array(samples[i..<min(i + frameSize, samples.count)])
            var energy: Float = 0.0
            vDSP_meamgv(frame, 1, &energy, vDSP_Length(frame.count))
            
            if energy > threshold {
                speechFrames += 1
                if currentPauseDuration > 0 {
                    pauseDurations.append(Float(currentPauseDuration) * Float(frameSize) / Float(sampleRate))
                    currentPauseDuration = 0
                }
            } else {
                silenceFrames += 1
                currentPauseDuration += 1
            }
        }
        
        let totalFrames = speechFrames + silenceFrames
        let speechPct = Float(speechFrames) / Float(totalFrames) * 100.0
        let silencePct = Float(silenceFrames) / Float(totalFrames) * 100.0
        let avgPause = pauseDurations.isEmpty ? 0 : pauseDurations.reduce(0, +) / Float(pauseDurations.count)
        
        return (speechPct, silencePct, avgPause)
    }
    
    private func amplitudeToDecibels(_ amplitude: Float) -> Float {
        return 20.0 * log10(max(amplitude, 0.00001))
    }
}
